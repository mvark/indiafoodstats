name: Fetch India Products on OFF from Hugging Face

on:
  workflow_dispatch:  # Manual trigger only

jobs:
  fetch:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install datasets pyarrow pandas

      - name: Fetch, filter, and save India products
        run: |
          python - <<'EOF'
          from datasets import load_dataset
          import pandas as pd
          from pathlib import Path
          import sys

          # === CONFIG ===
          DATASET_NAME = "openfoodfacts/product-database"
          SPLIT = "food"
          OUTPUT_FILE = Path("data/india_products.csv")
          CHUNK_SIZE = 5000

          OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

          # === SAFE STRING EXTRACTOR ===
          def safe_str(value):
              if isinstance(value, (list, tuple)):
                  return " ".join([str(x) for x in value if x is not None]).strip()
              return str(value or "").strip()

          # === FILTER FUNCTION ===
          def is_valid(record):
              try:
                  code = safe_str(record.get("code"))
                  name = safe_str(record.get("product_name"))
                  country = safe_str(record.get("countries_en"))

                  return code != "" and name != "" and country == "India"
              except:
                  return False

          # === FIELDS TO EXTRACT (all 17) ===
          FIELDS = [
              "code", "product_name", "brands", "categories",
              "energy-kcal_100g", "carbohydrates_100g", "sugars_100g", "fiber_100g",
              "proteins_100g", "fat_100g", "saturated-fat_100g", "salt_100g",
              "nova_group", "nutriscore_grade", "ingredients_text",
              "last_modified_datetime", "url"
          ]

          print(f"Loading dataset: {DATASET_NAME} (split: {SPLIT})")
          ds = load_dataset(DATASET_NAME, split=SPLIT, streaming=True)
          filtered = ds.filter(is_valid)

          header_written = False
          chunk = []
          total_saved = 0

          print("Streaming and filtering India products...")
          try:
              for record in filtered:
                  selected = {}
                  for k in FIELDS:
                      val = record.get(k)
                      if isinstance(val, (list, tuple)):
                          selected[k] = " | ".join([str(x) for x in val if x is not None])
                      else:
                          selected[k] = val
                  chunk.append(selected)

                  if len(chunk) >= CHUNK_SIZE:
                      df = pd.DataFrame(chunk)
                      mode = "a" if header_written else "w"
                      df.to_csv(OUTPUT_FILE, mode=mode, header=not header_written, index=False)
                      header_written = True
                      total_saved += len(chunk)
                      print(f"Saved chunk: {total_saved:,} rows")
                      chunk = []
          except Exception as e:
              print(f"Error during streaming: {e}")
              sys.exit(1)

          # Final chunk
          if chunk:
              df = pd
