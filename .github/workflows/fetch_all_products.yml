name: Fetch India Products on OFF from Hugging Face

on:
  workflow_dispatch:  # Manual trigger only

jobs:
  fetch:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install datasets pyarrow pandas

      - name: Fetch, filter, save CSV & update README
        id: fetch
        run: |
          python - <<'EOF'
          from datasets import load_dataset
          import pandas as pd
          from pathlib import Path
          import os
          from datetime import datetime

          # === CONFIG ===
          DATASET_NAME = "openfoodfacts/product-database"
          SPLIT = "food"
          DATA_DIR = Path("data")
          README_PATH = DATA_DIR / "README.md"
          CHUNK_SIZE = 1000

          DATA_DIR.mkdir(exist_ok=True)

          # === HELPER: Safe string from list or scalar ===
          def safe_str(val):
              if isinstance(val, (list, tuple)):
                  return " ".join(str(x) for x in val if x).strip()
              return str(val or "").strip()

          # === FILTER: India + non-empty code/name ===
          def is_valid(record):
              try:
                  code = safe_str(record.get("code"))
                  name = safe_str(record.get("product_name"))
                  countries = safe_str(record.get("countries_en", "")).split()
                  return code and name and "India" in countries
              except:
                  return False

          # === FIELDS ===
          FIELDS = [
              "code", "product_name", "brands", "categories",
              "energy-kcal_100g", "carbohydrates_100g", "sugars_100g", "fiber_100g",
              "proteins_100g", "fat_100g", "saturated-fat_100g", "salt_100g",
              "nova_group", "nutriscore_grade", "ingredients_text",
              "last_modified_datetime", "url"
          ]

          print("Loading dataset...")
          ds = load_dataset(DATASET_NAME, split=SPLIT, streaming=True)
          filtered = ds.filter(is_valid)

          all_records = []
          for i, record in enumerate(filtered, 1):
              selected = {}
              for k in FIELDS:
                  val = record.get(k)
                  if isinstance(val, (list, tuple)):
                      selected[k] = " | ".join(str(x) for x in val if x)
                  else:
                      selected[k] = val
              all_records.append(selected)

              if i % 1000 == 0:
                  print(f"Collected {i:,} records...")

          if not all_records:
              print("No records matched the filter.")
              print("::set-output name=records::0")
              print("::set-output name=csv_file::none")
              EOF
              exit(0)

          df = pd.DataFrame(all_records)
          record_count = len(df)
          date_str = datetime.now().strftime("%Y%m%d")
          csv_filename = f"all_{date_str}_{record_count}.csv"
          csv_path = DATA_DIR / csv_filename

          # Save CSV
          df.to_csv(csv_path, index=False)
          print(f"SAVED: {record_count} records â†’ {csv_path}")

          # Update README.md
          table_row = f"| {date_str} | {record_count} | `{csv_filename}` |\n"
          if README_PATH.exists():
              with open(README_PATH, "a", encoding="utf-8") as f:
                  f.write(table_row)
              print(f"Appended to {README_PATH}")
          else:
              header = "# Data Log\n\n| Date | Record Count | File |\n|------|--------------|------|\n"
              with open(README_PATH, "w", encoding="utf-8") as f:
                  f.write(header + table_row)
              print(f"Created {README_PATH}")

          # Output for next steps
          print(f"::set-output name=records::{record_count}")
          print(f"::set-output name=csv_file::{csv_path}")
          EOF

      - name: Commit and push
        if: steps.fetch.outputs.csv_file != 'none'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/
          git commit -m "Add India products: ${{ steps.fetch.outputs.csv_file }} (${{ steps.fetch.outputs.records }} records)"
          git push
