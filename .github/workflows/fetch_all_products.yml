name: Fetch India Products on OFF from Hugging Face

on:
  workflow_dispatch:  # manual trigger
jobs:
  fetch-and-save:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # allow push to repo
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"
      
      - name: Install dependencies
        run: pip install pandas datasets pyarrow
      
      - name: Fetch data and save CSV
        run: |
          python << 'EOF'
          import os
          import pandas as pd
          from datetime import datetime, timezone
          from datasets import load_dataset
          
          # --- Config ---
          DATE_STR = datetime.now(timezone.utc).strftime("%Y-%m-%d")
          README_PATH = "data/readme.md"
          
          print("Loading dataset from Hugging Face...")
          
          try:
              # Load dataset using Hugging Face datasets library
              # Use 'food' split instead of 'train'
              dataset = load_dataset(
                  "openfoodfacts/product-database",
                  split="food",
                  streaming=True  # Stream mode - doesn't download entire file
              )
              
              print("Filtering for India products...")
              
              india_products = []
              batch_size = 1000
              count = 0
              
              # Process in streaming mode
              for example in dataset:
                  count += 1
                  if count % 10000 == 0:
                      print(f"Processed {count} records, found {len(india_products)} India products so far...")
                  
                  # Check if product has required fields
                  code = example.get('code')
                  product_name = example.get('product_name')
                  countries_tags = example.get('countries_tags')
                  
                  if not code or not product_name or not countries_tags:
                      continue
                  
                  # Check if India is in countries_tags
                  if not isinstance(countries_tags, list):
                      continue
                  
                  has_india = any('india' in str(country).lower() for country in countries_tags)
                  
                  if has_india:
                      # Extract product name
                      product_name_text = None
                      if isinstance(product_name, list) and len(product_name) > 0:
                          if isinstance(product_name[0], dict):
                              product_name_text = product_name[0].get('text')
                      
                      # Extract ingredients text
                      ingredients_text_value = None
                      ingredients_text = example.get('ingredients_text')
                      if isinstance(ingredients_text, list) and len(ingredients_text) > 0:
                          if isinstance(ingredients_text[0], dict):
                              ingredients_text_value = ingredients_text[0].get('text')
                      
                      # Extract nutriments
                      nutriments = example.get('nutriments', [])
                      
                      def get_nutriment(nutriments_list, key):
                          if not isinstance(nutriments_list, list):
                              return None
                          for item in nutriments_list:
                              if isinstance(item, dict) and item.get('name') == key:
                                  return item.get('100g')
                          return None
                      
                      # Build record
                      record = {
                          'code': code,
                          'product_name': product_name_text,
                          'brands': example.get('brands'),
                          'categories': example.get('categories'),
                          'energy-kcal_100g': get_nutriment(nutriments, 'energy-kcal'),
                          'carbohydrates_100g': get_nutriment(nutriments, 'carbohydrates'),
                          'sugars_100g': get_nutriment(nutriments, 'sugars'),
                          'fiber_100g': get_nutriment(nutriments, 'fiber'),
                          'proteins_100g': get_nutriment(nutriments, 'proteins'),
                          'fat_100g': get_nutriment(nutriments, 'fat'),
                          'saturated-fat_100g': get_nutriment(nutriments, 'saturated-fat'),
                          'salt_100g': get_nutriment(nutriments, 'salt'),
                          'nova_group': example.get('nova_group'),
                          'nutriscore_grade': example.get('nutriscore_grade'),
                          'url': example.get('link'),
                          'last_modified_t': example.get('last_modified_t'),
                          'ingredients_text': ingredients_text_value
                      }
                      
                      india_products.append(record)
                      
                      # Save periodically to avoid memory issues
                      if len(india_products) >= batch_size:
                          print(f"Collected {len(india_products)} products, continuing...")
              
              print(f"Total products processed: {count}")
              print(f"Total India products found: {len(india_products)}")
              
          except Exception as e:
              print(f"Error loading dataset: {e}")
              import traceback
              traceback.print_exc()
              exit(1)
          
          # --- Convert to DataFrame ---
          if not india_products:
              print("No India products found. Exiting without saving.")
              exit(0)
          
          df_result = pd.DataFrame(india_products)
          
          # Convert timestamp to datetime
          if 'last_modified_t' in df_result.columns:
              df_result['last_modified_datetime'] = pd.to_datetime(
                  df_result['last_modified_t'], 
                  unit='s', 
                  errors='coerce'
              )
              df_result = df_result.drop('last_modified_t', axis=1)
          
          # --- Save CSV ---
          record_count = len(df_result)
          csv_filename = f"all_{DATE_STR}_{record_count}.csv"
          csv_path = os.path.join("data", csv_filename)
          os.makedirs("data", exist_ok=True)
          
          df_result.to_csv(csv_path, index=False)
          print(f"Saved {record_count} records to {csv_path}")
          
          # --- Update README.md ---
          note = f"| {DATE_STR} | {record_count} | `{csv_filename}` |\n"
          
          if os.path.exists(README_PATH):
              with open(README_PATH, "a", encoding="utf-8") as f:
                  f.write(note)
          else:
              with open(README_PATH, "w", encoding="utf-8") as f:
                  f.write("# Data Log\n\n")
                  f.write("| Date | Record Count | File |\n")
                  f.write("|------|--------------|------|\n")
                  f.write(note)
          
          print(f"Updated {README_PATH}")
          EOF
      
      - name: Commit and push changes
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/
          git commit -m "Fetched all India products on $(date -u +'%Y-%m-%d')" || echo "No changes"
          git push
